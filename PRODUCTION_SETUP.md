# GranblueParty: Complete Setup & Production Deployment Guide

## Overview

GranblueParty is a three-tier application for building Granblue Fantasy parties:

1. **WikiParser** (Python) - Scrapes wiki data and stores in PostgreSQL
2. **API** (Node.js/Express) - REST backend serving game data
3. **Frontend** (Vue.js/Node.js SSR) - Web UI for party building

This guide covers local setup and production deployment.

---

## Prerequisites

### System Requirements

#### All Tiers

- **PostgreSQL 14+** - Main database
- **Git** - Version control

#### WikiParser

- **Python 3.8+** (tested on 3.12)
- **Chrome/Chromium browser** - For Cloudflare-protected wiki scraping
- **geckodriver** or similar (optional, not recommended due to Cloudflare detection)

#### API & Frontend

- **Node.js 16+** (tested on 24.4.1)
- **npm** (bundled with Node.js)

### Network Access

- Wiki access: `https://gbf.wiki` (Cloudflare-protected)
- Database: `localhost:5432` (can be remote)

---

## Part 1: PostgreSQL Database Setup

### 1.1 Install PostgreSQL

**Windows:**

- Download from https://www.postgresql.org/download/windows/
- During installation, remember the `postgres` superuser password

**Linux/Mac:**

```bash
# Ubuntu/Debian
sudo apt-get install postgresql postgresql-contrib

# macOS with Homebrew
brew install postgresql@14
```

### 1.2 Create Database and User

```sql
-- Connect as postgres superuser
psql -U postgres

-- Inside psql:
CREATE DATABASE gbf;
CREATE USER pguser WITH PASSWORD 'gbfparser';
ALTER ROLE pguser SET client_encoding TO 'utf8';
ALTER ROLE pguser SET default_transaction_isolation TO 'read committed';
ALTER ROLE pguser SET default_transaction_deferrable TO on;
ALTER ROLE pguser SET timezone TO 'UTC';
GRANT ALL PRIVILEGES ON DATABASE gbf TO pguser;
\q
```

**Verify connection:**

```bash
psql -h localhost -U pguser -d gbf
```

---

## Part 2: WikiParser Setup

### 2.1 Install Python Dependencies

```bash
cd WikiParser
pip install -r requirements.txt
```

**Key packages:**

- `selenium` - Web automation
- `undetected-chromedriver` - Bypass Cloudflare detection
- `psycopg2-binary` - PostgreSQL connection
- `mwparserfromhell` - MediaWiki template parsing
- `Pillow` - Image processing

### 2.2 Configure WikiParser

**Copy and edit config:**

```bash
cp config/config.ini.template config/config.ini
```

**config.ini example:**

```ini
[postgresql]
host=localhost
database=gbf
user=pguser
password=gbfparser
port=5432

[path]
frontend=../Frontend
previews=preview
```

### 2.3 Create Database Schema

```bash
cd WikiParser
python database.py --create
python database.py --update
```

This creates:

- 33 tables (Character, Summon, Weapon, Class, etc.)
- Relationships (skills, auras, ougis, etc.)
- Loads initial CSV data from `db/` folder

### 2.4 Download Wiki Data (First Time Only)

```bash
# Download wiki pages and cache them locally
python parse.py -d
```

**What happens:**

1. Opens Chrome browser with Cloudflare warmup
2. **YOU MUST** press Enter after Cloudflare challenge passes and JSON is visible
3. Downloads ~1000 wiki pages for characters, summons, weapons, class skills
4. Saves raw wiki markup to `data/cache/`
5. Creates JSON files: `characters.json`, `summons.json`, `weapons.json`, `class_skill.json`

### 2.5 Parse Wiki Data into Database

```bash
# Parse cached wiki data and populate database
python parse.py --all
```

**What happens:**

1. Reads cached wiki JSON files
2. Parses MediaWiki templates (extracts stats, skills, auras, etc.)
3. Cleans HTML comments from template values (bugfix applied)
4. Drops and rebuilds all data tables
5. Downloads skill/aura icons to `Frontend/src/img/`
6. Total: ~961 characters, 363 summons, 1931 weapons, 76 classes

**Takes:** 10-30 minutes depending on system speed

### 2.6 Download Portrait Images

```bash
# Download character/summon/weapon portraits
python update_img.py
```

**What happens:**

- Reads URLs from `data/*.images` files (generated by parse.py)
- Downloads portraits from `prd-game-a-granbluefantasy.akamaized.net`
- Saves to `Frontend/src/img/unit/`, `unit_small/`, etc.
- Only downloads new files (incremental)

**Takes:** 5-15 minutes (2000+ images)

### 2.7 Future Updates (Incremental)

**Check for wiki changes:**

```bash
python parse.py -d
```

Only downloads pages that changed on the wiki (revision tracking). Much faster than first run.

**Reparse if changes found:**

```bash
python parse.py --all
```

**Download new images:**

```bash
python update_img.py
```

---

## Part 3: API Server Setup

### 3.1 Install Node Dependencies

```bash
cd API
npm install
```

### 3.2 Configure API

**Copy and edit config:**

```bash
cp src/config.js.template src/config.js
```

**config.js for local development:**

```javascript
const config = {
  frontend: {
    url: 'http://localhost',
    port: 4000, // Frontend port
  },
  app: {
    port: 3000, // API port
  },
  db: {
    host: 'localhost',
    port: 5432,
    name: 'gbf',
    user: 'pguser',
    password: 'gbfparser',
    versionFile: '/absolute/path/to/db.version', // From root
  },
  jwt: {
    secret: 'my secret secret', // Change this!
    BCRYPT_SALT_ROUNDS: 12,
    secureCookie: false, // true for HTTPS production
  },
  mailinjet: {
    public_key: '', // Optional: for password reset emails
    private_key: '',
  },
  logs: 'API/logs',
};

module.exports = config;
```

### 3.3 Run API

**Development mode (with auto-reload):**

```bash
npm start
```

**Production mode:**

```bash
npm run build
npm run serve
```

Server listens on `http://localhost:3000`

**Test API:**

```bash
curl http://localhost:3000/characters?search=Charlotte
```

---

## Part 4: Frontend Setup

### 4.1 Install Node Dependencies

```bash
cd Frontend
npm install
```

### 4.2 Configure Frontend

**Create config files:**

```bash
cp src/js/config.js.template src/js/config.js
cp src/js/config-server.js.template src/js/config-server.js
```

**config.js (client-side):**

```javascript
const config = {
  app: {
    baseURL: 'http://localhost:3000', // API URL
    timeout: 5000,
  },
};
module.exports = config;
```

**config-server.js (server-side):**

```javascript
const config = {
  server: {
    jwt: 'my secret secret', // Must match API secret
  },
};
module.exports = config;
```

### 4.3 Build Frontend

```bash
npm run build
```

Creates:

- `dist_new/` - Production-ready build
- Server bundle, client bundle, static assets

### 4.4 Run Frontend

**Production mode:**

```bash
npm start
```

Server listens on `http://localhost:4000`

Open browser: `http://localhost:4000`

---

## Part 5: Production Deployment Checklist

### 5.1 Pre-Deployment

- [ ] Update all API secrets and JWT keys (strong random values)
- [ ] Set `secureCookie: true` in API config if using HTTPS
- [ ] Verify database backups are configured
- [ ] Test all features locally
- [ ] Run `python parse.py -d` to ensure wiki is current
- [ ] Verify all images are downloaded

### 5.2 Server Infrastructure

**Recommended setup:**

- **Database:** PostgreSQL on dedicated server or managed service (AWS RDS, etc.)
- **API:** Node.js behind reverse proxy (Nginx/Apache)
- **Frontend:** Node.js SSR behind reverse proxy (Nginx/Apache)
- **Static files:** CDN or served from same instance

**Hardware:**

- **CPU:** 2+ cores
- **RAM:** 2GB+ per application
- **Disk:** 50GB+ for images and database

### 5.3 Reverse Proxy (Nginx) Example

```nginx
# /etc/nginx/sites-available/granblue.party

upstream api {
  server localhost:3000;
}

upstream frontend {
  server localhost:4000;
}

server {
  listen 80;
  server_name granblue.party www.granblue.party;

  # Redirect HTTP to HTTPS
  return 301 https://$server_name$request_uri;
}

server {
  listen 443 ssl http2;
  server_name granblue.party www.granblue.party;

  ssl_certificate /path/to/cert.pem;
  ssl_certificate_key /path/to/key.pem;

  # API endpoints
  location /api/ {
    proxy_pass http://api;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
  }

  # Frontend
  location / {
    proxy_pass http://frontend;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
  }
}
```

### 5.4 Process Management (systemd)

**Create `/etc/systemd/system/granblue-api.service`:**

```ini
[Unit]
Description=GranblueParty API
After=network.target postgresql.service

[Service]
Type=simple
User=gbf
WorkingDirectory=/opt/GranblueParty/API
Environment="NODE_ENV=production"
ExecStart=/usr/bin/npm run serve
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

**Create `/etc/systemd/system/granblue-frontend.service`:**

```ini
[Unit]
Description=GranblueParty Frontend
After=network.target

[Service]
Type=simple
User=gbf
WorkingDirectory=/opt/GranblueParty/Frontend
Environment="NODE_ENV=production"
ExecStart=/usr/bin/npm start
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

**Enable and start:**

```bash
sudo systemctl daemon-reload
sudo systemctl enable granblue-api granblue-frontend
sudo systemctl start granblue-api granblue-frontend
```

### 5.5 Database Backups

**Weekly backup script** (`/opt/backup-granblue.sh`):

```bash
#!/bin/bash
BACKUP_DIR="/backups/granblue"
DATE=$(date +%Y%m%d_%H%M%S)

mkdir -p $BACKUP_DIR
pg_dump -h localhost -U pguser gbf | gzip > $BACKUP_DIR/gbf_$DATE.sql.gz

# Keep only last 30 days
find $BACKUP_DIR -type f -mtime +30 -delete
```

**Add to crontab:**

```bash
0 3 * * 0 /opt/backup-granblue.sh  # Weekly at 3 AM Sunday
```

### 5.6 Monitoring & Logging

**Log locations:**

- **API:** `API/logs/`
- **Frontend:** STDOUT (capture with systemd journal)
- **Database:** PostgreSQL logs (varies by OS)

**View logs:**

```bash
# API logs
tail -f API/logs/*.log

# systemd logs
journalctl -u granblue-api -f
journalctl -u granblue-frontend -f
```

---

## Part 6: Maintenance & Updates

### 6.1 Wiki Data Updates (Weekly/Monthly)

```bash
cd WikiParser

# Check for wiki changes
python parse.py -d

# If changes exist, reparse
python parse.py --all

# Download any new images
python update_img.py

# Restart API to reload cache
sudo systemctl restart granblue-api
```

### 6.2 Database Maintenance

**Monthly maintenance:**

```bash
# Connect to database
psql -h localhost -U pguser -d gbf

-- Check database size
SELECT pg_size_pretty(pg_database_size('gbf'));

-- Cleanup old data
VACUUM ANALYZE;

-- Check for bloated tables
SELECT schemaname, tablename,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename))
FROM pg_tables
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
```

### 6.3 Deploy Code Updates

```bash
cd /opt/GranblueParty

# Pull latest code
git pull origin main

# Install dependencies
cd API && npm install
cd ../Frontend && npm install

# Rebuild frontend
npm run build

# Restart services
sudo systemctl restart granblue-api granblue-frontend
```

---

## Part 7: Troubleshooting

### API won't start: "Cannot contact database"

**Solution:**

1. Verify PostgreSQL is running: `sudo systemctl status postgresql`
2. Test connection: `psql -h localhost -U pguser -d gbf`
3. Check config: Verify host, port, user, password in `API/src/config.js`
4. Check firewall: Ensure port 5432 is accessible

### Frontend shows blank images

**Solution:**

1. Verify images downloaded: `ls Frontend/dist_new/img/unit/ | wc -l` (should be > 100)
2. Verify image paths: Check network tab in browser DevTools
3. Rebuild frontend: `cd Frontend && npm run build`
4. Restart frontend: `sudo systemctl restart granblue-frontend`

### Wiki scraping fails: "Cloudflare challenge"

**Solution:**

1. Ensure Chrome/Chromium is installed
2. Run `python parse.py -d` and manually pass Cloudflare when prompted
3. Press Enter only after JSON data is visible in browser
4. If stuck, increase timeout in `config/wikirequest.py` (line ~50)

### Database bloat after many updates

**Solution:**

```bash
psql -h localhost -U pguser -d gbf -c "VACUUM FULL ANALYZE;"
```

---

## Performance Tuning

### PostgreSQL

**Edit `/etc/postgresql/14/main/postgresql.conf`:**

```
# For 4GB+ RAM servers
shared_buffers = 1GB
effective_cache_size = 3GB
maintenance_work_mem = 256MB
random_page_cost = 1.1
```

Restart: `sudo systemctl restart postgresql`

### Node.js API

**Increase max connections in `API/src/config.js`:**

```javascript
// Add connection pool settings
db: {
  // ... existing config ...
  max: 20,  // Max connections
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 2000,
}
```

### Frontend

**Enable gzip compression in production:**

- Nginx handles automatically
- Verify: `curl -H "Accept-Encoding: gzip" http://localhost:4000 | file -`

---

## Security Considerations

### 1. Environment Variables (Production)

Instead of hardcoding secrets, use environment variables:

**API `src/config.js`:**

```javascript
const config = {
  db: {
    password: process.env.DB_PASSWORD || 'gbfparser',
  },
  jwt: {
    secret: process.env.JWT_SECRET || 'my secret secret',
  },
  // ...
};
```

**Set environment:**

```bash
export DB_PASSWORD="<strong-password>"
export JWT_SECRET="<64-char-random-string>"
```

### 2. Database Security

```sql
-- Restrict pguser to least privileges
REVOKE ALL ON DATABASE gbf FROM pguser;
GRANT CONNECT ON DATABASE gbf TO pguser;
GRANT USAGE ON SCHEMA public TO pguser;
GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO pguser;
```

### 3. API Rate Limiting

Add to `API/src/index.js`:

```javascript
import rateLimit from 'express-rate-limit';

const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 100, // Limit each IP to 100 requests per windowMs
});

app.use('/api/', limiter);
```

### 4. HTTPS/TLS

- Use Let's Encrypt: `sudo certbot certonly --nginx`
- Auto-renew: `sudo certbot renew --dry-run`
- Set `secureCookie: true` in API config

---

## Performance Metrics (Baseline)

Tested on local machine (Intel i7, 16GB RAM, SSD):

| Operation                     | Time         |
| ----------------------------- | ------------ |
| `parse.py -d` (first run)     | ~30 minutes  |
| `parse.py -d` (incremental)   | ~2 minutes   |
| `parse.py --all`              | ~15 minutes  |
| `update_img.py` (first run)   | ~15 minutes  |
| `update_img.py` (incremental) | ~1-2 minutes |
| Frontend build                | ~30 seconds  |
| API startup                   | ~2 seconds   |
| Character search (API)        | <100ms       |

---

## Summary: Complete Deployment Flow

### Local Development (Windows/Mac/Linux)

```bash
# 1. Setup database
createdb gbf
createuser pguser  # Set password

# 2. Setup WikiParser
cd WikiParser
pip install -r requirements.txt
cp config/config.ini.template config/config.ini
# Edit config.ini
python database.py --create
python database.py --update
python parse.py -d        # Pass Cloudflare when prompted
python parse.py --all     # 15-30 min
python update_img.py      # 10-15 min

# 3. Setup API
cd ../API
npm install
cp src/config.js.template src/config.js
# Edit src/config.js
npm start                 # Terminal 1

# 4. Setup Frontend
cd ../Frontend
npm install
cp src/js/config.js.template src/js/config.js
cp src/js/config-server.js.template src/js/config-server.js
# Edit both config files
npm run build             # Build once
npm start                 # Terminal 2

# 5. Access
# Open http://localhost:4000
```

### Production Deployment

```bash
# 1. Server setup (Ubuntu 20.04)
sudo apt update
sudo apt install postgresql nodejs npm nginx

# 2. Database
sudo -u postgres psql << EOF
CREATE DATABASE gbf;
CREATE USER pguser WITH PASSWORD 'strong-password';
GRANT ALL PRIVILEGES ON DATABASE gbf TO pguser;
EOF

# 3. Clone and setup code
git clone https://github.com/neobreakya/GranblueParty.git /opt/GranblueParty
cd /opt/GranblueParty/WikiParser
# ... follow setup above ...

# 4. Setup services (systemd)
sudo cp /opt/GranblueParty/docs/systemd/* /etc/systemd/system/
sudo systemctl enable granblue-api granblue-frontend
sudo systemctl start granblue-api granblue-frontend

# 5. Setup Nginx reverse proxy
sudo cp /opt/GranblueParty/docs/nginx/granblue.conf /etc/nginx/sites-available/
sudo ln -s /etc/nginx/sites-available/granblue.conf /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl restart nginx

# 6. Setup SSL with Let's Encrypt
sudo certbot certonly --nginx -d granblue.party -d www.granblue.party

# 7. Access
# https://granblue.party
```

---

## Support & Resources

- **GBF Wiki:** https://gbf.wiki/
- **Granblue Project:** https://github.com/neobreakya/GranblueParty
- **PostgreSQL Docs:** https://www.postgresql.org/docs/
- **Node.js Docs:** https://nodejs.org/en/docs/
- **Vue.js Docs:** https://vuejs.org/

---

**Last Updated:** January 2, 2026
**Version:** 2.1.0
